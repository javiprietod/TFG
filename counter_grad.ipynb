{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import src.utils\n",
    "import src.models\n",
    "import src.counterfactual\n",
    "\n",
    "importlib.reload(src.utils)\n",
    "importlib.reload(src.models)\n",
    "importlib.reload(src.counterfactual)\n",
    "\n",
    "from src.utils import load_data, load_model, DatasetMetadata, clean_instance\n",
    "from src.counterfactual import newton_op, distance, unscale_instance\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "# str to sympy\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from src.models import LogisticModel\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# device = device if not torch.backends.mps.is_available() else torch.device(\"mps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, model, metadata, max_epochs, dx_scaled, mean_scaled, upd_weights):\n",
    "        self.model: LogisticModel = model\n",
    "        self.metadata: DatasetMetadata = metadata\n",
    "        self.dx_scaled: torch.Tensor = dx_scaled\n",
    "        self.mean_scaled: torch.Tensor = mean_scaled\n",
    "        self.epochs: int = 0\n",
    "        self.max_epochs: int = max_epochs\n",
    "        self.upd_weights: torch.Tensor = upd_weights # columns to be updated\n",
    "        self.apply_reg = False # When to apply integer regularization\n",
    "        self.reg_vars = False # When to apply nÂº variables regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/Loan_default.csv'\n",
    "model_name = \"model_small\"\n",
    "model_dict = \"models/\"+model_name+\".pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "test_data: DataLoader\n",
    "train_data, _, test_data, _, metadata = load_data(filename, batch_size=1024)\n",
    "\n",
    "inputs = next(iter(test_data))[0].to(torch.float32).to(device)\n",
    "\n",
    "# define model\n",
    "model = load_model(model_name).to(torch.float32).to(device)\n",
    "\n",
    "torch.save(model.state_dict(), model_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract model equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sympy as sp\n",
    "# import torch\n",
    "# from sympy.parsing.sympy_parser import parse_expr\n",
    "\n",
    "# def extract_symbolic_equation(model: torch.nn.Module, instance: torch.Tensor):\n",
    "#     \"\"\"\n",
    "#     Extracts a symbolic equation from a trained PyTorch model.\n",
    "#     Assumes a feedforward structure with linear layers and activations.\n",
    "#     \"\"\"\n",
    "#     # Define symbolic variables for input features\n",
    "#     x2, x3 = sp.symbols('x2 x3')  # Inputs\n",
    "#     # constants = sp.symbols(f'c1:{model.input_dim + 1}')  # Constants for other features\n",
    "    \n",
    "#     # Build input vector with constants\n",
    "#     x = [instance[i].item() if i not in [1, 2] else (x2 if i == 1 else x3) for i in range(model.input_dim)]\n",
    "    \n",
    "#     # Convert to a sympy matrix\n",
    "#     X = sp.Matrix(x)\n",
    "#     activations = []\n",
    "\n",
    "#     # Iterate over layers\n",
    "#     for layer in model.layers:\n",
    "#         if isinstance(layer, torch.nn.Linear):\n",
    "#             W = sp.Matrix(layer.weight.detach().numpy())  # Extract weight matrix\n",
    "#             b = sp.Matrix(layer.bias.detach().numpy())    # Extract bias\n",
    "#             X = W * X + b  # Apply linear transformation\n",
    "#         elif isinstance(layer, torch.nn.ReLU):\n",
    "#             activations.append(X)\n",
    "#             X = X.applyfunc(lambda val: sp.Max(0, val))  # ReLU activation\n",
    "#         elif isinstance(layer, torch.nn.Sigmoid):\n",
    "#             activations.append(X)\n",
    "#             X = X.applyfunc(lambda val: 1 / (1 + sp.exp(-val)))  # Sigmoid activation\n",
    "#         # X.subs({sp.symbols(f'c{i+1}'): val for i, val in enumerate(inputs[0]) if i != 1 and i != 2})\n",
    "#         print(\"Done: \", layer)\n",
    "#         # print(X)\n",
    "\n",
    "\n",
    "#     # Apply softmax at the end\n",
    "#     denominator = sp.Add(*(sp.exp(e) for e in X))\n",
    "#     softmax_expr = sp.Matrix([sp.exp(e) / denominator for e in X])\n",
    "\n",
    "#     return softmax_expr, activations # .simplify()\n",
    "\n",
    "# # Example usage\n",
    "# model_sym = LogisticModel(inputs.shape[1], hidden_sizes=[16, 8])\n",
    "# model_sym.load_state_dict(torch.load(model_dict))  # Load trained weights\n",
    "# symbolic_eq, activations = extract_symbolic_equation(model_sym, inputs[0])\n",
    "# model_eq = symbolic_eq[0]\n",
    "# print(symbolic_eq)\n",
    "# # with open('small.txt', 'w') as f:\n",
    "# #     f.write(str(symbolic_eq))\n",
    "# with open('small.txt', 'r') as f:\n",
    "#     symbolic_eq1 = f.read()\n",
    "#     symbolic_eq1 = parse_expr(symbolic_eq1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "person: torch.Tensor = inputs[0].to(torch.float32).to(device)\n",
    "outputs = model(inputs).argmax(dim=1)\n",
    "inputs_useful = inputs[outputs == 1]\n",
    "# metadata.cols_for_mask = [True] * 100 + [False] * (len(metadata.cols_for_mask) - 100)\n",
    "# metadata.cols_for_mask = [True] * len(metadata.cols_for_mask)\n",
    "# metadata.cols_for_mask[1] = True\n",
    "# metadata.cols_for_mask[2] = True\n",
    "# metadata.cols_for_mask[3] = True\n",
    "# metadata.cols_for_mask[4] = True\n",
    "# metadata.cols_for_mask[5] = True\n",
    "# metadata.cols_for_mask[6] = True\n",
    "# metadata.cols_for_mask[7] = True\n",
    "# metadata.cols_for_mask[8] = True\n",
    "\n",
    "weights = torch.tensor(metadata.cols_for_mask, dtype=torch.float32).to(device)\n",
    "# weights = torch.ones_like(inputs_useful[0], dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = inputs_useful[0].to(torch.float32).to(device)\n",
    "# weights = torch.tensor([0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import src.counterfactual\n",
    "\n",
    "# importlib.reload(src.counterfactual)\n",
    "# from src.counterfactual import newton_op, distance\n",
    "# person = inputs_useful[0]\n",
    "# p_new, state_p = newton_op(model, person, metadata, weights, 0.1, reg_int=False, reg_vars=False, reg_clamp=True, print_=False)\n",
    "# torch.manual_seed(torch.randint(0, 100, (1,)).item())\n",
    "# n = 5\n",
    "# num_points = 10000\n",
    "# num_linspace = 5000\n",
    "# indexes = torch.nonzero(weights).reshape(-1)\n",
    "# print(indexes)\n",
    "# sampled_indexes = torch.tensor([6, 8]) # indexes #[torch.randint(0, len(indexes), (n,))]\n",
    "# print(sampled_indexes)\n",
    "\n",
    "# for sample_var in sampled_indexes:\n",
    "#     w = weights.clone()\n",
    "#     w[sample_var] = 0\n",
    "#     print(\"Sampled variable:\", sample_var.item())\n",
    "#     x = p_new.repeat(num_points*num_linspace, 1)\n",
    "#     print(\"points repeated\")\n",
    "#     # print(\"x:\", x[:, w != 0])\n",
    "\n",
    "#     # print(x)\n",
    "#     x[:, w != 0] = (torch.distributions.uniform.Uniform(metadata.min_values, metadata.max_values).sample((num_points,)) * w)[:, w != 0].repeat(num_linspace, 1)\n",
    "#     print(\"points generated\")\n",
    "\n",
    "#     x[:, sample_var] = torch.linspace(metadata.min_values[sample_var], metadata.max_values[sample_var], num_linspace).repeat(num_points)\n",
    "#     print(\"linspace generated\")\n",
    "\n",
    "#     x = x[model(x)[:, 0] > metadata.threshold]\n",
    "#     print(\"model filtered\")\n",
    "\n",
    "#     # calculate the distance\n",
    "#     dists = distance(person, x, weights, state_p, with_sum=False)\n",
    "#     print(torch.min(dists), distance(person, p_new, weights, state_p))\n",
    "#     x = x[dists < distance(person, p_new, weights, state_p)]\n",
    "#     print(\"distance filtered\")\n",
    "#     print(len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only 1 person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "ONLY MODEL DERIVATIVE: 0.05711791664361954\n",
      "Changes:  delta1: -0.15528741478919983  delta_l: 0.0\n",
      "dist: 0.10394056886434555 , threshold: 0.2816452980041504\n",
      "Epoch: 1\n",
      "ONLY MODEL DERIVATIVE: 0.09744583815336227\n",
      "Changes:  delta1: -0.13539542257785797  delta_l: 0.0\n",
      "dist: 0.3648679852485657 , threshold: 0.22263136506080627\n",
      "Epoch: 2\n",
      "ONLY MODEL DERIVATIVE: 0.1574321985244751\n",
      "Changes:  delta1: -0.10684225708246231  delta_l: 0.0\n",
      "dist: 0.6833893656730652 , threshold: 0.15195104479789734\n",
      "Epoch: 3\n",
      "Changes:  delta1: -0.19220706820487976  delta_l: -5.7508745193481445\n",
      "dist: 1.5147488117218018 , threshold: -0.04436570405960083\n",
      "Epoch: 4\n",
      "Changes:  delta1: -7.619365078426199e-06  delta_l: 2.3715884685516357\n",
      "dist: 1.351460337638855 , threshold: -0.0009301900863647461\n",
      "Epoch: 5\n",
      "Changes:  delta1: 5.775530054208389e-11  delta_l: 0.05691205710172653\n",
      "dist: 1.3479050397872925 , threshold: -5.960464477539062e-07\n",
      "Epoch: 6\n",
      "Changes:  delta1: 5.775642117344937e-11  delta_l: 6.262936949497089e-05\n",
      "dist: 1.3479028940200806 , threshold: -5.960464477539063e-08\n",
      "Epoch: 7\n",
      "Changes:  delta1: 5.7756448929024984e-11  delta_l: 4.3031624841205485e-07\n",
      "dist: 1.347902536392212 , threshold: 0.0\n",
      "Epoch: 8\n",
      "Changes:  delta1: 0.012786849401891232  delta_l: -0.07732152193784714\n",
      "dist: 0.42056310176849365 , threshold: -1.2814998626708984e-05\n",
      "Epoch: 9\n",
      "Changes:  delta1: -3.802196079050191e-05  delta_l: 0.0002896734804380685\n",
      "dist: 0.42051321268081665 , threshold: 5.960464477539063e-08\n",
      "Epoch: 10\n",
      "Changes:  delta1: 1.7450942380037304e-07  delta_l: -1.4696888683829457e-06\n",
      "dist: 0.42051342129707336 , threshold: -5.960464477539063e-08\n",
      "Original output: tensor([[0.1776, 0.8224]], grad_fn=<DifferentiableGraphBackward>)\n",
      "New output: tensor([[0.5000, 0.5000]], grad_fn=<DifferentiableGraphBackward>)\n",
      "Regularization strength: 3.8956010341644287\n",
      "Epochs: 11\n",
      "Valid: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>MonthsEmployed</th>\n",
       "      <th>NumCreditLines</th>\n",
       "      <th>InterestRate</th>\n",
       "      <th>LoanTerm</th>\n",
       "      <th>DTIRatio</th>\n",
       "      <th>Education_High School</th>\n",
       "      <th>...</th>\n",
       "      <th>EmploymentType_Unemployed</th>\n",
       "      <th>MaritalStatus_Married</th>\n",
       "      <th>MaritalStatus_Single</th>\n",
       "      <th>HasMortgage_Yes</th>\n",
       "      <th>HasDependents_Yes</th>\n",
       "      <th>LoanPurpose_Business</th>\n",
       "      <th>LoanPurpose_Education</th>\n",
       "      <th>LoanPurpose_Home</th>\n",
       "      <th>LoanPurpose_Other</th>\n",
       "      <th>HasCoSigner_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>121621.0</td>\n",
       "      <td>76545.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.823526</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.677917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age    Income  LoanAmount  CreditScore  MonthsEmployed  NumCreditLines  \\\n",
       "0  19.0  121621.0     76545.0        563.0            64.0             4.0   \n",
       "\n",
       "   InterestRate  LoanTerm  DTIRatio  Education_High School  ...  \\\n",
       "0     17.823526      60.0  0.677917                    0.0  ...   \n",
       "\n",
       "   EmploymentType_Unemployed  MaritalStatus_Married  MaritalStatus_Single  \\\n",
       "0                        0.0                    0.0                   1.0   \n",
       "\n",
       "   HasMortgage_Yes  HasDependents_Yes  LoanPurpose_Business  \\\n",
       "0              0.0                0.0                   0.0   \n",
       "\n",
       "   LoanPurpose_Education  LoanPurpose_Home  LoanPurpose_Other  HasCoSigner_Yes  \n",
       "0                    0.0               0.0                1.0              0.0  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import src.counterfactual\n",
    "import src.checks\n",
    "\n",
    "importlib.reload(src.counterfactual)\n",
    "importlib.reload(src.checks)\n",
    "from src.counterfactual import newton_op\n",
    "from src.checks import Checks\n",
    "\n",
    "reg_int=True\n",
    "reg_clamp=True\n",
    "\n",
    "metadata.threshold = 0.5 + 1e-7\n",
    "person = inputs_useful[6]\n",
    "p_new, _ = newton_op(model, person, metadata, weights, 0.2, reg_int=reg_int, reg_clamp=reg_clamp, print_=True)\n",
    "p = person.clone().detach()\n",
    "check = Checks(model, metadata, reg_int=reg_int, reg_clamp=reg_clamp, dataset=next(iter(train_data))[0])\n",
    "valid = check(person, p_new, weights)\n",
    "print(\"Valid:\", valid)\n",
    "display(pd.DataFrame([unscale_instance(p_new, metadata).detach().numpy()], columns=metadata.columns))\n",
    "# print(model(p_new.unsqueeze(0))[0][metadata.good_class].item(), model(p_new.unsqueeze(0)).argmax(dim=1))\n",
    "# if check.sorted_points is not None:\n",
    "#     minimal = torch.tensor(check.sorted_points.iloc[0, :-2].values).float()\n",
    "#     print(distance(person, p_new, weights).item(), distance(person, minimal, weights).item())\n",
    "#     display(pd.DataFrame(unscale_batch(torch.tensor(check.sorted_points.to_numpy()[:, :-2]).float(), metadata), columns=metadata.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 person, different weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.])\n",
      "Epoch: 0\n",
      "ONLY MODEL DERIVATIVE: 0.0828336551785469\n",
      "Changes:  delta1: -0.13978469371795654  delta_l: 0.0\n",
      "dist: 0.08863423019647598 , threshold: 0.24497714638710022\n",
      "Epoch: 1\n",
      "ONLY MODEL DERIVATIVE: 0.1373034566640854\n",
      "Changes:  delta1: -0.11506202071905136  delta_l: 0.0\n",
      "dist: 0.29451456665992737 , threshold: 0.17655232548713684\n",
      "Epoch: 2\n",
      "Changes:  delta1: -0.24510157108306885  delta_l: -5.36952018737793\n",
      "dist: 1.130959391593933 , threshold: -0.07328683137893677\n",
      "Epoch: 3\n",
      "Changes:  delta1: 1.162972785095917e-05  delta_l: 3.02851939201355\n",
      "dist: 0.9077669978141785 , threshold: -0.0018201470375061035\n",
      "Epoch: 4\n",
      "Changes:  delta1: 8.847264587608095e-11  delta_l: 0.030933715403079987\n",
      "dist: 0.9026430249214172 , threshold: -2.1457672119140625e-06\n",
      "Epoch: 5\n",
      "Changes:  delta1: 8.847574062276209e-11  delta_l: 5.725659502786584e-05\n",
      "dist: 0.9026370644569397 , threshold: -5.960464477539063e-08\n",
      "Epoch: 6\n",
      "Changes:  delta1: 8.847588633953407e-11  delta_l: 1.0513600727790617e-06\n",
      "dist: 0.9026368260383606 , threshold: 0.0\n",
      "Epoch: 7\n",
      "Changes:  delta1: 0.009801479056477547  delta_l: -0.05787377804517746\n",
      "dist: 0.2350279986858368 , threshold: -7.68899917602539e-06\n",
      "Epoch: 8\n",
      "Changes:  delta1: -2.2557911506737582e-05  delta_l: 0.00021856045350432396\n",
      "dist: 0.23500600457191467 , threshold: 5.960464477539063e-08\n",
      "Epoch: 9\n",
      "Changes:  delta1: 1.732572059154336e-07  delta_l: -1.1596569038374582e-06\n",
      "dist: 0.23500610888004303 , threshold: 0.0\n",
      "Original output: tensor([[0.2023, 0.7977]], grad_fn=<DifferentiableGraphBackward>)\n",
      "New output: tensor([[0.5000, 0.5000]], grad_fn=<DifferentiableGraphBackward>)\n",
      "Regularization strength: 2.863922119140625\n",
      "Epochs: 10\n",
      "tensor(27946.5469, grad_fn=<DivBackward0>)\n",
      "Valid1: True\n",
      "tensor([0., 2., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.])\n",
      "Epoch: 0\n",
      "ONLY MODEL DERIVATIVE: 0.0828336551785469\n",
      "Changes:  delta1: -0.13978469371795654  delta_l: 0.0\n",
      "dist: 0.10817399621009827 , threshold: 0.24497714638710022\n",
      "Epoch: 1\n",
      "ONLY MODEL DERIVATIVE: 0.1373034566640854\n",
      "Changes:  delta1: -0.11506202071905136  delta_l: 0.0\n",
      "dist: 0.35946139693260193 , threshold: 0.17655232548713684\n",
      "Epoch: 2\n",
      "Changes:  delta1: -0.026128597557544708  delta_l: -6.14890193939209\n",
      "dist: 1.2714073657989502 , threshold: -0.07309222221374512\n",
      "Epoch: 3\n",
      "Changes:  delta1: -9.624435733712744e-06  delta_l: 3.4267971515655518\n",
      "dist: 1.024906873703003 , threshold: -0.0018065571784973145\n",
      "Epoch: 4\n",
      "Changes:  delta1: 9.718422594451326e-11  delta_l: 0.030262161046266556\n",
      "dist: 1.0191330909729004 , threshold: -2.205371856689453e-06\n",
      "Epoch: 5\n",
      "Changes:  delta1: 9.718737620234563e-11  delta_l: 4.93755069328472e-05\n",
      "dist: 1.019126057624817 , threshold: 1.1920928955078125e-07\n",
      "Epoch: 6\n",
      "Changes:  delta1: 9.718729293561879e-11  delta_l: -1.3279317272463231e-06\n",
      "dist: 1.0191264152526855 , threshold: 0.0\n",
      "Epoch: 7\n",
      "Changes:  delta1: 0.011083586141467094  delta_l: -0.06537432968616486\n",
      "dist: 0.3031209707260132 , threshold: -9.715557098388672e-06\n",
      "Epoch: 8\n",
      "Changes:  delta1: -2.8525086236186326e-05  delta_l: 0.0002466311270836741\n",
      "dist: 0.3030894100666046 , threshold: 0.0\n",
      "Epoch: 9\n",
      "Changes:  delta1: 1.0079287404707316e-09  delta_l: -6.0916143240774545e-09\n",
      "dist: 0.3030894100666046 , threshold: 0.0\n",
      "Original output: tensor([[0.2023, 0.7977]], grad_fn=<DifferentiableGraphBackward>)\n",
      "New output: tensor([[0.5000, 0.5000]], grad_fn=<DifferentiableGraphBackward>)\n",
      "Regularization strength: 3.2531793117523193\n",
      "Epochs: 10\n",
      "tensor(17942.3477, grad_fn=<DivBackward0>)\n",
      "Valid2: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>MonthsEmployed</th>\n",
       "      <th>NumCreditLines</th>\n",
       "      <th>InterestRate</th>\n",
       "      <th>LoanTerm</th>\n",
       "      <th>DTIRatio</th>\n",
       "      <th>Education_High School</th>\n",
       "      <th>...</th>\n",
       "      <th>EmploymentType_Unemployed</th>\n",
       "      <th>MaritalStatus_Married</th>\n",
       "      <th>MaritalStatus_Single</th>\n",
       "      <th>HasMortgage_Yes</th>\n",
       "      <th>HasDependents_Yes</th>\n",
       "      <th>LoanPurpose_Business</th>\n",
       "      <th>LoanPurpose_Education</th>\n",
       "      <th>LoanPurpose_Home</th>\n",
       "      <th>LoanPurpose_Other</th>\n",
       "      <th>HasCoSigner_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>29467.0</td>\n",
       "      <td>151769.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.630000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.0</td>\n",
       "      <td>48946.0</td>\n",
       "      <td>121685.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.442996</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.464706</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td>40415.0</td>\n",
       "      <td>117950.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.010474</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.462681</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age   Income  LoanAmount  CreditScore  MonthsEmployed  NumCreditLines  \\\n",
       "0  19.0  29467.0    151769.0        606.0            33.0             1.0   \n",
       "1  19.0  48946.0    121685.0        633.0            49.0             1.0   \n",
       "2  19.0  40415.0    117950.0        636.0            52.0             1.0   \n",
       "\n",
       "   InterestRate  LoanTerm  DTIRatio  Education_High School  ...  \\\n",
       "0      6.630000      24.0  0.480000                    1.0  ...   \n",
       "1      3.442996      24.0  0.464706                    1.0  ...   \n",
       "2      3.010474      24.0  0.462681                    1.0  ...   \n",
       "\n",
       "   EmploymentType_Unemployed  MaritalStatus_Married  MaritalStatus_Single  \\\n",
       "0                        1.0                    0.0                   1.0   \n",
       "1                        1.0                    0.0                   1.0   \n",
       "2                        1.0                    0.0                   1.0   \n",
       "\n",
       "   HasMortgage_Yes  HasDependents_Yes  LoanPurpose_Business  \\\n",
       "0              1.0                0.0                   1.0   \n",
       "1              1.0                0.0                   1.0   \n",
       "2              1.0                0.0                   1.0   \n",
       "\n",
       "   LoanPurpose_Education  LoanPurpose_Home  LoanPurpose_Other  HasCoSigner_Yes  \n",
       "0                    0.0               0.0                0.0              0.0  \n",
       "1                    0.0               0.0                0.0              0.0  \n",
       "2                    0.0               0.0                0.0              0.0  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import src.counterfactual\n",
    "\n",
    "importlib.reload(src.counterfactual)\n",
    "from src.counterfactual import newton_op\n",
    "\n",
    "reg_int=True\n",
    "reg_clamp=False\n",
    "check = Checks(model, metadata, reg_int=reg_int, reg_clamp=reg_clamp)\n",
    "\n",
    "person = inputs_useful[1]\n",
    "\n",
    "weights1 = weights.clone()\n",
    "print(weights1)\n",
    "p_new1, state_p = newton_op(model, person, metadata, weights1, 0.2, reg_int=reg_int, reg_clamp=reg_clamp, print_=True)\n",
    "valid1 = check(person, p_new, weights)\n",
    "print(\"Valid1:\", valid1)\n",
    "\n",
    "weights2 = weights.clone()\n",
    "weights2[1] = 2\n",
    "print(weights2)\n",
    "p_new2, state_p = newton_op(model, person, metadata, weights2, 0.2, reg_int=reg_int, reg_clamp=reg_clamp, print_=True)\n",
    "valid2 = check(person, p_new, weights)\n",
    "print(\"Valid2:\", valid2)\n",
    "\n",
    "display(pd.DataFrame([unscale_instance(person, metadata).detach().numpy(), unscale_instance(p_new1, metadata).detach().numpy(), unscale_instance(p_new2, metadata).detach().numpy()], columns=metadata.columns))\n",
    "# display(check.sorted_points)\n",
    "# print(model(p_new.unsqueeze(0))[0][metadata.good_class].item(), model(p_new.unsqueeze(0)).argmax(dim=1))\n",
    "# if check.sorted_points is not None:\n",
    "#     minimal = torch.tensor(check.sorted_points.iloc[0, :-2].values).float()\n",
    "#     print(distance(person, p_new, weights).item(), distance(person, minimal, weights).item())\n",
    "#     display(pd.DataFrame(unscale_batch(torch.tensor(check.sorted_points.to_numpy()[:, :-2]).float(), metadata), columns=metadata.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 person, different flags (clamp, int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import src.counterfactual\n",
    "\n",
    "# importlib.reload(src.counterfactual)\n",
    "# from src.counterfactual import newton_op, distance, unscale_instance, scale_instance\n",
    "# person = inputs_useful[47]\n",
    "# person_new, state = newton_op(model, person, metadata, weights, 0.1, print_=True)\n",
    "# person_new_clamp, _ = newton_op(model, person, metadata, weights, 0.1, reg_clamp=True, print_=True)\n",
    "# person_new_int, _ = newton_op(model, person, metadata, weights, reg_int=True, print_=True)\n",
    "# person_new_clamp_int, _ = newton_op(model, person, metadata, weights, 0.1, reg_int=True, reg_clamp=True, print_=True)\n",
    "# # person_new_vars, _ = newton_op(model, person, metadata, weights, reg_vars=True, print_=True)\n",
    "# # person_new_int_vars, _ = newton_op(model, person, metadata, weights, 0.1, reg_int=True, reg_vars=True, print_=True)\n",
    "\n",
    "# names = ['person', 'person_new', 'person_new_clamp','person_new_int', 'person_new_clamp_int']\n",
    "# ps = [eval(i) for i in names]\n",
    "# outputs = [model(p.unsqueeze(0))[0][metadata.good_class].item() for p in ps]\n",
    "\n",
    "# distances = [distance(person, p, weights, state=state).item() for p in ps]\n",
    "\n",
    "# a = pd.DataFrame([unscale_instance(x, metadata).detach().cpu().numpy().reshape(-1) for x in ps], columns=metadata.columns)\n",
    "# a['output'] = outputs\n",
    "# a['distance'] = distances\n",
    "# # set index\n",
    "# a['names'] = names\n",
    "# a = a.set_index('names')\n",
    "# print(a.columns)\n",
    "# a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person: 0 Time: 0.03498062497237697 s\n",
      "Person: 1 Time: 0.024592834000941366 s\n",
      "Person: 2 Time: 0.023454791982658207 s\n",
      "Person: 3 Time: 0.01598016597563401 s\n",
      "Person: 4 Time: 0.0363622090080753 s\n",
      "Person: 5 Time: 0.01630404096795246 s\n",
      "Person: 6 Time: 0.031305333017371595 s\n",
      "Person: 7 Time: 0.026613374997396022 s\n",
      "Person: 8 Time: 0.026215707999654114 s\n",
      "Person: 9 Time: 0.020610959036275744 s\n",
      "Person: 10 Time: 0.02429954201215878 s\n",
      "Person: 11 Time: 0.029072375036776066 s\n",
      "Person: 12 Time: 0.03063470800407231 s\n",
      "Person: 13 Time: 0.020688374992460012 s\n",
      "Person: 14 Time: 0.019534000020939857 s\n",
      "Person: 15 Time: 0.023705292027443647 s\n",
      "Person: 16 Time: 0.021956415963359177 s\n",
      "Person: 17 Time: 0.026825707987882197 s\n",
      "Person: 18 Time: 0.02642929198918864 s\n",
      "Person: 19 Time: 0.021233165985904634 s\n",
      "Person: 20 Time: 0.022055500012356788 s\n",
      "Person: 21 Time: 0.01629433297784999 s\n",
      "Person: 22 Time: 0.02514075004728511 s\n",
      "Person: 23 Time: 0.02792491699801758 s\n",
      "Person: 24 Time: 0.022228166984859854 s\n",
      "Person: 25 Time: 0.026460500026587397 s\n",
      "Person: 26 Time: 0.027132791990879923 s\n",
      "Person: 27 Time: 0.02562545903492719 s\n",
      "Person: 28 Time: 0.0358778330264613 s\n",
      "Person: 29 Time: 0.050354667007923126 s\n",
      "Person: 30 Time: 0.028997332963626832 s\n",
      "Person: 31 Time: 0.04259045800426975 s\n",
      "Person: 32 Time: 0.026188082993030548 s\n",
      "Person: 33 Time: 0.03414783300831914 s\n",
      "Person: 34 Time: 0.019557541992980987 s\n",
      "Person: 35 Time: 0.02383529202779755 s\n",
      "Person: 36 Time: 0.01765904203057289 s\n",
      "Person: 37 Time: 0.021103291015606374 s\n",
      "Person: 38 Time: 0.03328508301638067 s\n",
      "Person: 39 Time: 0.027498000010382384 s\n",
      "Person: 40 Time: 0.02854316699085757 s\n",
      "Person: 41 Time: 0.03539099998306483 s\n",
      "Person: 42 Time: 0.03284237498883158 s\n",
      "Person: 43 Time: 0.02724654204212129 s\n",
      "Person: 44 Time: 0.020992457983084023 s\n",
      "Person: 45 Time: 0.03379191702697426 s\n",
      "Person: 46 Time: 0.03534120903350413 s\n",
      "Person: 47 Time: 0.022108583012595773 s\n",
      "Person: 48 Time: 0.03887220798060298 s\n",
      "Person: 49 Time: 0.026794750010594726 s\n",
      "Person: 50 Time: 0.01624837500276044 s\n",
      "Person: 51 Time: 0.024654374981764704 s\n",
      "Person: 52 Time: 0.027041541994549334 s\n",
      "Person: 53 Time: 0.019991124980151653 s\n",
      "Person: 54 Time: 0.02972758299438283 s\n",
      "Person: 55 Time: 0.02084583300165832 s\n",
      "Person: 56 Time: 0.019632874988019466 s\n",
      "Person: 57 Time: 0.023672792012803257 s\n",
      "Person: 58 Time: 0.02246645902050659 s\n",
      "Person: 59 Time: 0.027560957998503 s\n",
      "Person: 60 Time: 0.026044042024295777 s\n",
      "Person: 61 Time: 0.026272375020198524 s\n",
      "Person: 62 Time: 0.01880537497345358 s\n",
      "Person: 63 Time: 0.032113416003994644 s\n",
      "Person: 64 Time: 0.01800583297153935 s\n",
      "Person: 65 Time: 0.021474583016242832 s\n",
      "Person: 66 Time: 0.037433666002471 s\n",
      "Person: 67 Time: 0.03201416600495577 s\n",
      "Person: 68 Time: 0.02952958398964256 s\n",
      "Person: 69 Time: 0.024723582959268242 s\n",
      "Person: 70 Time: 0.016650207981001586 s\n",
      "Person: 71 Time: 0.021189625025726855 s\n",
      "Person: 72 Time: 0.016132417018525302 s\n",
      "Person: 73 Time: 0.0324847919982858 s\n",
      "Person: 74 Time: 0.02496962499571964 s\n",
      "Person: 75 Time: 0.021369250025600195 s\n",
      "Person: 76 Time: 0.02998587500769645 s\n",
      "Person: 77 Time: 0.02126249996945262 s\n",
      "Person: 78 Time: 0.02520566596649587 s\n",
      "Person: 79 Time: 0.031146958004683256 s\n",
      "Person: 80 Time: 0.023212167026940733 s\n",
      "Person: 81 Time: 0.025630166986957192 s\n",
      "Person: 82 Time: 0.021408333035651594 s\n",
      "Person: 83 Time: 0.0419588329968974 s\n",
      "Person: 84 Time: 0.021357999998144805 s\n",
      "Person: 85 Time: 0.024920083000324667 s\n",
      "Person: 86 Time: 0.021013999998103827 s\n",
      "Person: 87 Time: 0.01719537499593571 s\n",
      "Person: 88 Time: 0.03068779199384153 s\n",
      "Person: 89 Time: 0.022879958036355674 s\n",
      "Person: 90 Time: 0.030173790990374982 s\n",
      "Person: 91 Time: 0.025752499990630895 s\n",
      "Person: 92 Time: 0.02938654099125415 s\n",
      "Person: 93 Time: 0.02914970798883587 s\n",
      "Person: 94 Time: 0.03294100001221523 s\n",
      "Person: 95 Time: 0.02524412499042228 s\n",
      "Person: 96 Time: 0.024372540996409953 s\n",
      "Person: 97 Time: 0.01755004102597013 s\n",
      "Person: 98 Time: 0.024547707987949252 s\n",
      "Person: 99 Time: 0.019422375014983118 s\n",
      "Person: 100 Time: 0.03589804196963087 s\n",
      "Person: 101 Time: 0.02334220800548792 s\n",
      "Person: 102 Time: 0.02824925002641976 s\n",
      "Person: 103 Time: 0.019059375044889748 s\n",
      "Person: 104 Time: 0.03479150001658127 s\n",
      "Person: 105 Time: 0.031962082954123616 s\n",
      "Person: 106 Time: 0.026318542018998414 s\n",
      "Person: 107 Time: 0.01954604097409174 s\n",
      "Person: 108 Time: 0.03204012505011633 s\n",
      "Person: 109 Time: 0.020753666991367936 s\n",
      "Person: 110 Time: 0.03179741697385907 s\n",
      "Person: 111 Time: 0.02180975000374019 s\n",
      "Person: 112 Time: 0.017550582997500896 s\n",
      "Person: 113 Time: 0.03425895899999887 s\n",
      "Person: 114 Time: 0.023898250015918165 s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[151], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerson:\u001b[39m\u001b[38;5;124m\"\u001b[39m, idx, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m s\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# if time > 0.2 else '')\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# TODO: poner la minimalidad\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m successes \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m valid \u001b[38;5;66;03m# and (((state_p.metadata.max_values < p_new) | (state_p.metadata.min_values > p_new)).sum() == 0))\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# print(\"Person:\", idx, \"Rate of grad desc:\",minimality_check(p, p_new, weights, ep, model))\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/TFG/src/checks.py:76\u001b[0m, in \u001b[0;36mChecks.__call__\u001b[0;34m(self, person, person_new, weights)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe new person is an outlier.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstability_check_global\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperson_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model is not stable around this point\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/TFG/src/checks.py:244\u001b[0m, in \u001b[0;36mChecks.stability_check_global\u001b[0;34m(self, person, person_new, weights)\u001b[0m\n\u001b[1;32m    234\u001b[0m points \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m    235\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m-\u001b[39mnoise, noise, (num_points, person\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;241m*\u001b[39m (weights \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy() \n\u001b[1;32m    237\u001b[0m     \u001b[38;5;241m+\u001b[39m person\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    238\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32,\n\u001b[1;32m    239\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m person_close \u001b[38;5;129;01min\u001b[39;00m points:\n\u001b[0;32m--> 244\u001b[0m     person_close_new, _ \u001b[38;5;241m=\u001b[39m \u001b[43mnewton_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperson_close\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreg_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg_clamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreg_clamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m     diff_factor \u001b[38;5;241m=\u001b[39m distance(person_new, person_close_new, weights) \u001b[38;5;241m/\u001b[39m distance(person, person_close, weights)\n\u001b[1;32m    246\u001b[0m     max_diff_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(max_diff_factor, diff_factor)\n",
      "File \u001b[0;32m~/Documents/TFG/src/counterfactual.py:292\u001b[0m, in \u001b[0;36mnewton_op\u001b[0;34m(model, person, metadata, weights, delta_threshold, max_epochs, reg_int, reg_vars, reg_clamp, print_, der)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat((cost_func \u001b[38;5;241m-\u001b[39m l \u001b[38;5;241m*\u001b[39m restriction, l_derivative))\n\u001b[1;32m    291\u001b[0m fpl \u001b[38;5;241m=\u001b[39m fpl_func(person_new, l)\n\u001b[0;32m--> 292\u001b[0m jac_tuple \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpl_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mperson_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(jac_tuple[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mord\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m<\u001b[39m delta_threshold:\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;66;03m###################################################\u001b[39;00m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;66;03m### Problemas con la hessiana\u001b[39;00m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;66;03m###################################################\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;66;03m# ponderamos salto a como de lejos estemos\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     delta \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    300\u001b[0m         thres_term\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m         )\n\u001b[1;32m    310\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/autograd/functional.py:673\u001b[0m, in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m    672\u001b[0m     is_inputs_tuple, inputs \u001b[38;5;241m=\u001b[39m _as_tuple(inputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 673\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43m_grad_preprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    675\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m    676\u001b[0m     is_outputs_tuple, outputs \u001b[38;5;241m=\u001b[39m _as_tuple(\n\u001b[1;32m    677\u001b[0m         outputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs of the user-provided function\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    678\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/autograd/functional.py:87\u001b[0m, in \u001b[0;36m_grad_preprocess\u001b[0;34m(inputs, create_graph, need_graph)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m         res\u001b[38;5;241m.\u001b[39mappend(inp\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mrequires_grad_(need_graph))\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(res)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import src.counterfactual\n",
    "import src.checks\n",
    "importlib.reload(src.counterfactual)\n",
    "importlib.reload(src.checks)\n",
    "from src.counterfactual import newton_op\n",
    "from src.checks import Checks\n",
    "\n",
    "reg_int = True\n",
    "reg_clamp = True\n",
    "metadata.threshold = 0.5 + 1e-7\n",
    "\n",
    "successes = 0\n",
    "epochs = 0\n",
    "bad_idxs = []\n",
    "total = 0\n",
    "total_time = []\n",
    "check = Checks(model, metadata, reg_int=reg_int, reg_clamp=reg_clamp)\n",
    "for idx, p in enumerate(inputs_useful[:176]):\n",
    "\n",
    "    from time import perf_counter\n",
    "    \n",
    "    s = perf_counter()\n",
    "    p_new, ep = newton_op(model, p, metadata, weights, 0.2, reg_int=reg_int, reg_clamp=reg_clamp, der=False)\n",
    "    time = perf_counter()-s\n",
    "    print(\"Person:\", idx, f'Time: {time} s') # if time > 0.2 else '')\n",
    "    # TODO: poner la minimalidad\n",
    "    valid = check(p, p_new, weights)\n",
    "    successes += valid # and (((state_p.metadata.max_values < p_new) | (state_p.metadata.min_values > p_new)).sum() == 0))\n",
    "    # print(\"Person:\", idx, \"Rate of grad desc:\",minimality_check(p, p_new, weights, ep, model))\n",
    "    epochs += ep.epochs\n",
    "    total += 1\n",
    "    total_time.append(time)\n",
    "    # if not valid:\n",
    "    #     bad_idxs.append(idx)\n",
    "        # print(idx, valid)\n",
    "print(\"Successes:\", successes, \"Total:\", total)\n",
    "print(\"Average epochs:\", epochs / total)\n",
    "print(\"Time:\", np.array(total_time).mean() , np.array(total_time).std() )\n",
    "print(\"Stability:\", np.array(check.diff_factors).mean(), 'Â±', np.array(check.diff_factors).std())\n",
    "print(\"Success rate:\", successes / total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan 4.353627812117338 Â± 5.806163177495694"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# successes = 0\n",
    "# bad_idxs = []\n",
    "# total = 0\n",
    "# for i, inputs in enumerate(test_data):\n",
    "#     print(i, end='\\r')\n",
    "#     outputs = model(inputs[0]).argmax(dim=1)\n",
    "#     inputs_useful = inputs[0][outputs == 1]\n",
    "#     for idx, p in enumerate(inputs_useful):\n",
    "#         _, ep = newton_op(model, p, weights, 0.1) #if idx not in [103, 105, 237, 406, 417, 450] else None\n",
    "#         # print(\"Person:\", idx, \"Success:\", not ep)\n",
    "#         successes += ep\n",
    "#         total += 1\n",
    "#         # if not ep:\n",
    "#         #     bad_idxs.append(idx)\n",
    "#     print(successes/total)\n",
    "# print(\"Successes:\", successes, \"Total:\", total)\n",
    "# print(\"Success rate:\", successes / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epochs: 8.909090909090908\n",
      "Time: 0.03304126153869385 0.025611918371383748\n",
      "Stability: nan Â± nan\n",
      "Success rate: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Average epochs:\", epochs / total)\n",
    "print(\"Time:\", np.array(total_time).mean() , np.array(total_time).std() )\n",
    "print(\"Stability:\", np.array(check.diff_factors).mean(), 'Â±', np.array(check.diff_factors).std())\n",
    "print(\"Success rate:\", successes / total)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
