{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import src.utils\n",
    "import src.models\n",
    "import src.counterfactual\n",
    "\n",
    "importlib.reload(src.utils)\n",
    "importlib.reload(src.models)\n",
    "importlib.reload(src.counterfactual)\n",
    "\n",
    "from src.utils import load_data, load_model, DatasetMetadata, clean_instance\n",
    "from src.counterfactual import newton_op, distance, unscale_instance\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "# str to sympy\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from src.models import LogisticModel\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# device = device if not torch.backends.mps.is_available() else torch.device(\"mps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, model, metadata, max_epochs, dx_scaled, mean_scaled, upd_weights):\n",
    "        self.model: LogisticModel = model\n",
    "        self.metadata: DatasetMetadata = metadata\n",
    "        self.dx_scaled: torch.Tensor = dx_scaled\n",
    "        self.mean_scaled: torch.Tensor = mean_scaled\n",
    "        self.epochs: int = 0\n",
    "        self.max_epochs: int = max_epochs\n",
    "        self.upd_weights: torch.Tensor = upd_weights # columns to be updated\n",
    "        self.apply_reg = False # When to apply integer regularization\n",
    "        self.reg_vars = False # When to apply nº variables regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/Loan_default.csv'\n",
    "model_name = \"model_small\"\n",
    "model_dict = \"models/\"+model_name+\".pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "test_data: DataLoader\n",
    "train_data, _, test_data, _, metadata = load_data(filename, batch_size=1024)\n",
    "\n",
    "inputs = next(iter(test_data))[0].to(torch.float32).to(device)\n",
    "\n",
    "# define model\n",
    "model = load_model(model_name).to(torch.float32).to(device)\n",
    "\n",
    "torch.save(model.state_dict(), model_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract model equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sympy as sp\n",
    "# import torch\n",
    "# from sympy.parsing.sympy_parser import parse_expr\n",
    "\n",
    "# def extract_symbolic_equation(model: torch.nn.Module, instance: torch.Tensor):\n",
    "#     \"\"\"\n",
    "#     Extracts a symbolic equation from a trained PyTorch model.\n",
    "#     Assumes a feedforward structure with linear layers and activations.\n",
    "#     \"\"\"\n",
    "#     # Define symbolic variables for input features\n",
    "#     x2, x3 = sp.symbols('x2 x3')  # Inputs\n",
    "#     # constants = sp.symbols(f'c1:{model.input_dim + 1}')  # Constants for other features\n",
    "    \n",
    "#     # Build input vector with constants\n",
    "#     x = [instance[i].item() if i not in [1, 2] else (x2 if i == 1 else x3) for i in range(model.input_dim)]\n",
    "    \n",
    "#     # Convert to a sympy matrix\n",
    "#     X = sp.Matrix(x)\n",
    "#     activations = []\n",
    "\n",
    "#     # Iterate over layers\n",
    "#     for layer in model.layers:\n",
    "#         if isinstance(layer, torch.nn.Linear):\n",
    "#             W = sp.Matrix(layer.weight.detach().numpy())  # Extract weight matrix\n",
    "#             b = sp.Matrix(layer.bias.detach().numpy())    # Extract bias\n",
    "#             X = W * X + b  # Apply linear transformation\n",
    "#         elif isinstance(layer, torch.nn.ReLU):\n",
    "#             activations.append(X)\n",
    "#             X = X.applyfunc(lambda val: sp.Max(0, val))  # ReLU activation\n",
    "#         elif isinstance(layer, torch.nn.Sigmoid):\n",
    "#             activations.append(X)\n",
    "#             X = X.applyfunc(lambda val: 1 / (1 + sp.exp(-val)))  # Sigmoid activation\n",
    "#         # X.subs({sp.symbols(f'c{i+1}'): val for i, val in enumerate(inputs[0]) if i != 1 and i != 2})\n",
    "#         print(\"Done: \", layer)\n",
    "#         # print(X)\n",
    "\n",
    "\n",
    "#     # Apply softmax at the end\n",
    "#     denominator = sp.Add(*(sp.exp(e) for e in X))\n",
    "#     softmax_expr = sp.Matrix([sp.exp(e) / denominator for e in X])\n",
    "\n",
    "#     return softmax_expr, activations # .simplify()\n",
    "\n",
    "# # Example usage\n",
    "# model_sym = LogisticModel(inputs.shape[1], hidden_sizes=[16, 8])\n",
    "# model_sym.load_state_dict(torch.load(model_dict))  # Load trained weights\n",
    "# symbolic_eq, activations = extract_symbolic_equation(model_sym, inputs[0])\n",
    "# model_eq = symbolic_eq[0]\n",
    "# print(symbolic_eq)\n",
    "# # with open('small.txt', 'w') as f:\n",
    "# #     f.write(str(symbolic_eq))\n",
    "# with open('small.txt', 'r') as f:\n",
    "#     symbolic_eq1 = f.read()\n",
    "#     symbolic_eq1 = parse_expr(symbolic_eq1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "person: torch.Tensor = inputs[0].to(torch.float32).to(device)\n",
    "outputs = model(inputs).argmax(dim=1)\n",
    "inputs_useful = inputs[outputs == 1]\n",
    "# metadata.cols_for_mask = [True] * 100 + [False] * (len(metadata.cols_for_mask) - 100)\n",
    "# metadata.cols_for_mask = [False] * len(metadata.cols_for_mask)\n",
    "# metadata.cols_for_mask[1] = True\n",
    "# metadata.cols_for_mask[2] = True\n",
    "# metadata.cols_for_mask[3] = True\n",
    "# metadata.cols_for_mask[4] = True\n",
    "# metadata.cols_for_mask[5] = True\n",
    "# metadata.cols_for_mask[6] = True\n",
    "# metadata.cols_for_mask[7] = True\n",
    "# metadata.cols_for_mask[8] = True\n",
    "\n",
    "weights = torch.tensor(metadata.cols_for_mask, dtype=torch.float32).to(device)\n",
    "# weights = torch.ones_like(inputs_useful[0], dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = inputs_useful[0].to(torch.float32).to(device)\n",
    "# weights = torch.tensor([0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import src.counterfactual\n",
    "\n",
    "# importlib.reload(src.counterfactual)\n",
    "# from src.counterfactual import newton_op, distance\n",
    "# person = inputs_useful[0]\n",
    "# p_new, state_p = newton_op(model, person, metadata, weights, 0.1, reg_int=False, reg_vars=False, reg_clamp=True, print_=False)\n",
    "# torch.manual_seed(torch.randint(0, 100, (1,)).item())\n",
    "# n = 5\n",
    "# num_points = 10000\n",
    "# num_linspace = 5000\n",
    "# indexes = torch.nonzero(weights).reshape(-1)\n",
    "# print(indexes)\n",
    "# sampled_indexes = torch.tensor([6, 8]) # indexes #[torch.randint(0, len(indexes), (n,))]\n",
    "# print(sampled_indexes)\n",
    "\n",
    "# for sample_var in sampled_indexes:\n",
    "#     w = weights.clone()\n",
    "#     w[sample_var] = 0\n",
    "#     print(\"Sampled variable:\", sample_var.item())\n",
    "#     x = p_new.repeat(num_points*num_linspace, 1)\n",
    "#     print(\"points repeated\")\n",
    "#     # print(\"x:\", x[:, w != 0])\n",
    "\n",
    "#     # print(x)\n",
    "#     x[:, w != 0] = (torch.distributions.uniform.Uniform(metadata.min_values, metadata.max_values).sample((num_points,)) * w)[:, w != 0].repeat(num_linspace, 1)\n",
    "#     print(\"points generated\")\n",
    "\n",
    "#     x[:, sample_var] = torch.linspace(metadata.min_values[sample_var], metadata.max_values[sample_var], num_linspace).repeat(num_points)\n",
    "#     print(\"linspace generated\")\n",
    "\n",
    "#     x = x[model(x)[:, 0] > metadata.threshold]\n",
    "#     print(\"model filtered\")\n",
    "\n",
    "#     # calculate the distance\n",
    "#     dists = distance(person, x, weights, state_p, with_sum=False)\n",
    "#     print(torch.min(dists), distance(person, p_new, weights, state_p))\n",
    "#     x = x[dists < distance(person, p_new, weights, state_p)]\n",
    "#     print(\"distance filtered\")\n",
    "#     print(len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only 1 person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "zero-dimensional tensor (at position 0) cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m metadata\u001b[38;5;241m.\u001b[39mthreshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-7\u001b[39m\n\u001b[1;32m     13\u001b[0m person \u001b[38;5;241m=\u001b[39m inputs_useful[\u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m---> 14\u001b[0m p_new, _ \u001b[38;5;241m=\u001b[39m \u001b[43mnewton_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreg_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg_clamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreg_clamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m p \u001b[38;5;241m=\u001b[39m person\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     16\u001b[0m check \u001b[38;5;241m=\u001b[39m Checks(model, metadata, reg_int\u001b[38;5;241m=\u001b[39mreg_int, reg_clamp\u001b[38;5;241m=\u001b[39mreg_clamp, dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_data))[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/TFG/src/counterfactual.py:316\u001b[0m, in \u001b[0;36mnewton_op\u001b[0;34m(model, person, metadata, weights, delta_threshold, max_epochs, reg_int, reg_vars, reg_clamp, print_, der)\u001b[0m\n\u001b[1;32m    308\u001b[0m jac_tuple \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mjacobian(fpl_func, (person_new, l))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(jac_tuple[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mord\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m<\u001b[39m delta_threshold:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;66;03m###################################################\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;66;03m### Problemas con la hessiana\u001b[39;00m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;66;03m###################################################\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# ponderamos salto a como de lejos estemos\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     delta \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 316\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m                \u001b[49m\u001b[43mthres_term\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjac_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m     )\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mONLY MODEL DERIVATIVE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(jac_tuple[\u001b[38;5;241m1\u001b[39m],\u001b[38;5;250m \u001b[39m\u001b[38;5;28mord\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    327\u001b[0m     ) \u001b[38;5;28;01mif\u001b[39;00m print_ \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: zero-dimensional tensor (at position 0) cannot be concatenated"
     ]
    }
   ],
   "source": [
    "import src.counterfactual\n",
    "import src.checks\n",
    "\n",
    "importlib.reload(src.counterfactual)\n",
    "importlib.reload(src.checks)\n",
    "from src.counterfactual import newton_op\n",
    "from src.checks import Checks\n",
    "\n",
    "reg_int=False\n",
    "reg_clamp=False\n",
    "\n",
    "metadata.threshold = 0.5 + 1e-7\n",
    "person = inputs_useful[4]\n",
    "p_new, _ = newton_op(model, person, metadata, weights, 0.2, reg_int=reg_int, reg_clamp=reg_clamp, print_=True)\n",
    "p = person.clone().detach()\n",
    "check = Checks(model, metadata, reg_int=reg_int, reg_clamp=reg_clamp, dataset=next(iter(train_data))[0])\n",
    "valid = check(person, p_new, weights)\n",
    "print(\"Valid:\", valid)\n",
    "display(pd.DataFrame([unscale_instance(person, metadata).detach().numpy(), unscale_instance(p_new, metadata).detach().numpy()], columns=metadata.columns))\n",
    "# print(model(p_new.unsqueeze(0))[0][metadata.good_class].item(), model(p_new.unsqueeze(0)).argmax(dim=1))\n",
    "# if check.sorted_points is not None:\n",
    "#     minimal = torch.tensor(check.sorted_points.iloc[0, :-2].values).float()\n",
    "#     print(distance(person, p_new, weights).item(), distance(person, minimal, weights).item())\n",
    "#     display(pd.DataFrame(unscale_batch(torch.tensor(check.sorted_points.to_numpy()[:, :-2]).float(), metadata), columns=metadata.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 person, different weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.])\n",
      "Epoch: 0\n",
      "ONLY MODEL DERIVATIVE: 0.0828336551785469\n",
      "Changes:  delta1: -0.13978469371795654  delta_l: 0.0\n",
      "dist: 0.08863423019647598 , threshold: 0.24497714638710022\n",
      "Epoch: 1\n",
      "ONLY MODEL DERIVATIVE: 0.1373034566640854\n",
      "Changes:  delta1: -0.11506202071905136  delta_l: 0.0\n",
      "dist: 0.29451456665992737 , threshold: 0.17655232548713684\n",
      "Epoch: 2\n",
      "Changes:  delta1: -0.24510157108306885  delta_l: -5.36952018737793\n",
      "dist: 1.130959391593933 , threshold: -0.07328683137893677\n",
      "Epoch: 3\n",
      "Changes:  delta1: 1.162972785095917e-05  delta_l: 3.02851939201355\n",
      "dist: 0.9077669978141785 , threshold: -0.0018201470375061035\n",
      "Epoch: 4\n",
      "Changes:  delta1: 8.847264587608095e-11  delta_l: 0.030933715403079987\n",
      "dist: 0.9026430249214172 , threshold: -2.1457672119140625e-06\n",
      "Epoch: 5\n",
      "Changes:  delta1: 8.847574062276209e-11  delta_l: 5.725659502786584e-05\n",
      "dist: 0.9026370644569397 , threshold: -5.960464477539063e-08\n",
      "Epoch: 6\n",
      "Changes:  delta1: 8.847588633953407e-11  delta_l: 1.0513600727790617e-06\n",
      "dist: 0.9026368260383606 , threshold: 0.0\n",
      "Epoch: 7\n",
      "Changes:  delta1: 0.009801479056477547  delta_l: -0.05787377804517746\n",
      "dist: 0.2350279986858368 , threshold: -7.68899917602539e-06\n",
      "Epoch: 8\n",
      "Changes:  delta1: -2.2557911506737582e-05  delta_l: 0.00021856045350432396\n",
      "dist: 0.23500600457191467 , threshold: 5.960464477539063e-08\n",
      "Epoch: 9\n",
      "Changes:  delta1: 1.732572059154336e-07  delta_l: -1.1596569038374582e-06\n",
      "dist: 0.23500610888004303 , threshold: 0.0\n",
      "Original output: tensor([[0.2023, 0.7977]], grad_fn=<DifferentiableGraphBackward>)\n",
      "New output: tensor([[0.5000, 0.5000]], grad_fn=<DifferentiableGraphBackward>)\n",
      "Regularization strength: 2.863922119140625\n",
      "Epochs: 10\n",
      "tensor(27946.5469, grad_fn=<DivBackward0>)\n",
      "Valid1: True\n",
      "tensor([0., 2., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.])\n",
      "Epoch: 0\n",
      "ONLY MODEL DERIVATIVE: 0.0828336551785469\n",
      "Changes:  delta1: -0.13978469371795654  delta_l: 0.0\n",
      "dist: 0.10817399621009827 , threshold: 0.24497714638710022\n",
      "Epoch: 1\n",
      "ONLY MODEL DERIVATIVE: 0.1373034566640854\n",
      "Changes:  delta1: -0.11506202071905136  delta_l: 0.0\n",
      "dist: 0.35946139693260193 , threshold: 0.17655232548713684\n",
      "Epoch: 2\n",
      "Changes:  delta1: -0.026128597557544708  delta_l: -6.14890193939209\n",
      "dist: 1.2714073657989502 , threshold: -0.07309222221374512\n",
      "Epoch: 3\n",
      "Changes:  delta1: -9.624435733712744e-06  delta_l: 3.4267971515655518\n",
      "dist: 1.024906873703003 , threshold: -0.0018065571784973145\n",
      "Epoch: 4\n",
      "Changes:  delta1: 9.718422594451326e-11  delta_l: 0.030262161046266556\n",
      "dist: 1.0191330909729004 , threshold: -2.205371856689453e-06\n",
      "Epoch: 5\n",
      "Changes:  delta1: 9.718737620234563e-11  delta_l: 4.93755069328472e-05\n",
      "dist: 1.019126057624817 , threshold: 1.1920928955078125e-07\n",
      "Epoch: 6\n",
      "Changes:  delta1: 9.718729293561879e-11  delta_l: -1.3279317272463231e-06\n",
      "dist: 1.0191264152526855 , threshold: 0.0\n",
      "Epoch: 7\n",
      "Changes:  delta1: 0.011083586141467094  delta_l: -0.06537432968616486\n",
      "dist: 0.3031209707260132 , threshold: -9.715557098388672e-06\n",
      "Epoch: 8\n",
      "Changes:  delta1: -2.8525086236186326e-05  delta_l: 0.0002466311270836741\n",
      "dist: 0.3030894100666046 , threshold: 0.0\n",
      "Epoch: 9\n",
      "Changes:  delta1: 1.0079287404707316e-09  delta_l: -6.0916143240774545e-09\n",
      "dist: 0.3030894100666046 , threshold: 0.0\n",
      "Original output: tensor([[0.2023, 0.7977]], grad_fn=<DifferentiableGraphBackward>)\n",
      "New output: tensor([[0.5000, 0.5000]], grad_fn=<DifferentiableGraphBackward>)\n",
      "Regularization strength: 3.2531793117523193\n",
      "Epochs: 10\n",
      "tensor(17942.3477, grad_fn=<DivBackward0>)\n",
      "Valid2: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>MonthsEmployed</th>\n",
       "      <th>NumCreditLines</th>\n",
       "      <th>InterestRate</th>\n",
       "      <th>LoanTerm</th>\n",
       "      <th>DTIRatio</th>\n",
       "      <th>Education_High School</th>\n",
       "      <th>...</th>\n",
       "      <th>EmploymentType_Unemployed</th>\n",
       "      <th>MaritalStatus_Married</th>\n",
       "      <th>MaritalStatus_Single</th>\n",
       "      <th>HasMortgage_Yes</th>\n",
       "      <th>HasDependents_Yes</th>\n",
       "      <th>LoanPurpose_Business</th>\n",
       "      <th>LoanPurpose_Education</th>\n",
       "      <th>LoanPurpose_Home</th>\n",
       "      <th>LoanPurpose_Other</th>\n",
       "      <th>HasCoSigner_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>29467.0</td>\n",
       "      <td>151769.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.630000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.0</td>\n",
       "      <td>48946.0</td>\n",
       "      <td>121685.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.442996</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.464706</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td>40415.0</td>\n",
       "      <td>117950.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.010474</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.462681</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age   Income  LoanAmount  CreditScore  MonthsEmployed  NumCreditLines  \\\n",
       "0  19.0  29467.0    151769.0        606.0            33.0             1.0   \n",
       "1  19.0  48946.0    121685.0        633.0            49.0             1.0   \n",
       "2  19.0  40415.0    117950.0        636.0            52.0             1.0   \n",
       "\n",
       "   InterestRate  LoanTerm  DTIRatio  Education_High School  ...  \\\n",
       "0      6.630000      24.0  0.480000                    1.0  ...   \n",
       "1      3.442996      24.0  0.464706                    1.0  ...   \n",
       "2      3.010474      24.0  0.462681                    1.0  ...   \n",
       "\n",
       "   EmploymentType_Unemployed  MaritalStatus_Married  MaritalStatus_Single  \\\n",
       "0                        1.0                    0.0                   1.0   \n",
       "1                        1.0                    0.0                   1.0   \n",
       "2                        1.0                    0.0                   1.0   \n",
       "\n",
       "   HasMortgage_Yes  HasDependents_Yes  LoanPurpose_Business  \\\n",
       "0              1.0                0.0                   1.0   \n",
       "1              1.0                0.0                   1.0   \n",
       "2              1.0                0.0                   1.0   \n",
       "\n",
       "   LoanPurpose_Education  LoanPurpose_Home  LoanPurpose_Other  HasCoSigner_Yes  \n",
       "0                    0.0               0.0                0.0              0.0  \n",
       "1                    0.0               0.0                0.0              0.0  \n",
       "2                    0.0               0.0                0.0              0.0  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import src.counterfactual\n",
    "\n",
    "importlib.reload(src.counterfactual)\n",
    "from src.counterfactual import newton_op\n",
    "\n",
    "reg_int=True\n",
    "reg_clamp=False\n",
    "check = Checks(model, metadata, reg_int=reg_int, reg_clamp=reg_clamp)\n",
    "\n",
    "person = inputs_useful[1]\n",
    "\n",
    "weights1 = weights.clone()\n",
    "print(weights1)\n",
    "p_new1, state_p = newton_op(model, person, metadata, weights1, 0.2, reg_int=reg_int, reg_clamp=reg_clamp, print_=True)\n",
    "valid1 = check(person, p_new, weights)\n",
    "print(\"Valid1:\", valid1)\n",
    "\n",
    "weights2 = weights.clone()\n",
    "weights2[1] = 2\n",
    "print(weights2)\n",
    "p_new2, state_p = newton_op(model, person, metadata, weights2, 0.2, reg_int=reg_int, reg_clamp=reg_clamp, print_=True)\n",
    "valid2 = check(person, p_new, weights)\n",
    "print(\"Valid2:\", valid2)\n",
    "\n",
    "display(pd.DataFrame([unscale_instance(person, metadata).detach().numpy(), unscale_instance(p_new1, metadata).detach().numpy(), unscale_instance(p_new2, metadata).detach().numpy()], columns=metadata.columns))\n",
    "# display(check.sorted_points)\n",
    "# print(model(p_new.unsqueeze(0))[0][metadata.good_class].item(), model(p_new.unsqueeze(0)).argmax(dim=1))\n",
    "# if check.sorted_points is not None:\n",
    "#     minimal = torch.tensor(check.sorted_points.iloc[0, :-2].values).float()\n",
    "#     print(distance(person, p_new, weights).item(), distance(person, minimal, weights).item())\n",
    "#     display(pd.DataFrame(unscale_batch(torch.tensor(check.sorted_points.to_numpy()[:, :-2]).float(), metadata), columns=metadata.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 person, different flags (clamp, int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import src.counterfactual\n",
    "\n",
    "# importlib.reload(src.counterfactual)\n",
    "# from src.counterfactual import newton_op, distance, unscale_instance, scale_instance\n",
    "# person = inputs_useful[47]\n",
    "# person_new, state = newton_op(model, person, metadata, weights, 0.1, print_=True)\n",
    "# person_new_clamp, _ = newton_op(model, person, metadata, weights, 0.1, reg_clamp=True, print_=True)\n",
    "# person_new_int, _ = newton_op(model, person, metadata, weights, reg_int=True, print_=True)\n",
    "# person_new_clamp_int, _ = newton_op(model, person, metadata, weights, 0.1, reg_int=True, reg_clamp=True, print_=True)\n",
    "# # person_new_vars, _ = newton_op(model, person, metadata, weights, reg_vars=True, print_=True)\n",
    "# # person_new_int_vars, _ = newton_op(model, person, metadata, weights, 0.1, reg_int=True, reg_vars=True, print_=True)\n",
    "\n",
    "# names = ['person', 'person_new', 'person_new_clamp','person_new_int', 'person_new_clamp_int']\n",
    "# ps = [eval(i) for i in names]\n",
    "# outputs = [model(p.unsqueeze(0))[0][metadata.good_class].item() for p in ps]\n",
    "\n",
    "# distances = [distance(person, p, weights, state=state).item() for p in ps]\n",
    "\n",
    "# a = pd.DataFrame([unscale_instance(x, metadata).detach().cpu().numpy().reshape(-1) for x in ps], columns=metadata.columns)\n",
    "# a['output'] = outputs\n",
    "# a['distance'] = distances\n",
    "# # set index\n",
    "# a['names'] = names\n",
    "# a = a.set_index('names')\n",
    "# print(a.columns)\n",
    "# a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person: 0 Time: 0.021630458999425173 s\n",
      "Person: 1 Time: 0.019737166992854327 s\n",
      "Person: 2 Time: 0.015206416996079497 s\n",
      "Person: 3 Time: 0.013937083989731036 s\n",
      "Person: 4 Time: 0.01265054200484883 s\n",
      "Person: 5 Time: 0.012764792001689784 s\n",
      "Person: 6 Time: 0.03753741599211935 s\n",
      "Person: 7 Time: 0.033515832998091355 s\n",
      "Person: 8 Time: 0.014141708001261577 s\n",
      "Person: 9 Time: 0.015974834008375183 s\n",
      "Person: 10 Time: 0.02297170800738968 s\n",
      "Person: 11 Time: 0.01796445800573565 s\n",
      "Person: 12 Time: 0.013498917003744282 s\n",
      "Person: 13 Time: 0.016856916990946047 s\n",
      "Person: 14 Time: 0.01332699999329634 s\n",
      "Person: 15 Time: 0.01672349999716971 s\n",
      "Person: 16 Time: 0.016085541996289976 s\n",
      "Person: 17 Time: 0.036439084011362866 s\n",
      "Person: 18 Time: 0.014320916001452133 s\n",
      "Person: 19 Time: 0.016545082995435223 s\n",
      "Person: 20 Time: 0.016675124992616475 s\n",
      "Person: 21 Time: 0.009892207992379554 s\n",
      "Person: 22 Time: 0.01562575000571087 s\n",
      "Person: 23 Time: 0.015912332994048484 s\n",
      "Person: 24 Time: 0.017428833001758903 s\n",
      "Person: 25 Time: 0.01812574999348726 s\n",
      "Person: 26 Time: 0.01769958400109317 s\n",
      "Person: 27 Time: 0.013587249995907769 s\n",
      "Person: 28 Time: 0.014363249996677041 s\n",
      "Person: 29 Time: 0.0016162909887498245 s\n",
      "Person: 30 Time: 0.018019708004430868 s\n",
      "Person: 31 Time: 0.01797016699856613 s\n",
      "Person: 32 Time: 0.013786374998744577 s\n",
      "Person: 33 Time: 0.014244500009226613 s\n",
      "Person: 34 Time: 0.014140957995550707 s\n",
      "Person: 35 Time: 0.014499625001917593 s\n",
      "Person: 36 Time: 0.01796374999685213 s\n",
      "Person: 37 Time: 0.04016483300074469 s\n",
      "Person: 38 Time: 0.01245429199479986 s\n",
      "Person: 39 Time: 0.03781599999638274 s\n",
      "Person: 40 Time: 0.014264999990700744 s\n",
      "Person: 41 Time: 0.03462466600467451 s\n",
      "Person: 42 Time: 0.016490416004671715 s\n",
      "Person: 43 Time: 0.01889729200047441 s\n",
      "Person: 44 Time: 0.016890083003090695 s\n",
      "Person: 45 Time: 0.013195749997976236 s\n",
      "Person: 46 Time: 0.01678916699893307 s\n",
      "Person: 47 Time: 0.012605041993083432 s\n",
      "Person: 48 Time: 0.0013510419958038256 s\n",
      "Person: 49 Time: 0.018354500003624707 s\n",
      "Person: 50 Time: 0.01815929199801758 s\n",
      "Person: 51 Time: 0.020282208002754487 s\n",
      "Person: 52 Time: 0.019008499992196448 s\n",
      "Person: 53 Time: 0.012449875008314848 s\n",
      "Person: 54 Time: 0.016541290999157354 s\n",
      "Person: 55 Time: 0.013630332992761396 s\n",
      "Person: 56 Time: 0.011746542004402727 s\n",
      "Person: 57 Time: 0.01850170899706427 s\n",
      "Person: 58 Time: 0.013312208000570536 s\n",
      "Person: 59 Time: 0.013343124999664724 s\n",
      "Person: 60 Time: 0.017891083989525214 s\n",
      "Person: 61 Time: 0.01737058299477212 s\n",
      "Person: 62 Time: 0.01443729099992197 s\n",
      "Person: 63 Time: 0.016777541997726075 s\n",
      "Person: 64 Time: 0.014829708001343533 s\n",
      "Person: 65 Time: 0.015324833002523519 s\n",
      "Person: 66 Time: 0.015174957996350713 s\n",
      "Person: 67 Time: 0.03367258299840614 s\n",
      "Person: 68 Time: 0.013642459001857787 s\n",
      "Person: 69 Time: 0.014437958001508377 s\n",
      "Person: 70 Time: 0.011387749997084029 s\n",
      "Person: 71 Time: 0.013418583999737166 s\n",
      "Person: 72 Time: 0.011261583000305109 s\n",
      "Person: 73 Time: 0.012804083002265543 s\n",
      "Person: 74 Time: 0.016873542001121677 s\n",
      "Person: 75 Time: 0.014400000000023283 s\n",
      "Person: 76 Time: 0.20048641599714756 s\n",
      "Person: 77 Time: 0.017058666999218985 s\n",
      "Person: 78 Time: 0.017937625001650304 s\n",
      "Person: 79 Time: 0.015130040992517024 s\n",
      "Person: 80 Time: 0.02502766699763015 s\n",
      "Person: 81 Time: 0.0165184590005083 s\n",
      "Person: 82 Time: 0.016886375000467524 s\n",
      "Person: 83 Time: 0.00158004199329298 s\n",
      "Person: 84 Time: 0.017122666002251208 s\n",
      "Person: 85 Time: 0.014038207998964936 s\n",
      "Person: 86 Time: 0.016244332990027033 s\n",
      "Person: 87 Time: 0.01735512500454206 s\n",
      "Person: 88 Time: 0.015874999997322448 s\n",
      "Person: 89 Time: 0.017704540994600393 s\n",
      "Person: 90 Time: 0.018205999993369915 s\n",
      "Person: 91 Time: 0.036346207998576574 s\n",
      "Person: 92 Time: 0.03189879200363066 s\n",
      "Person: 93 Time: 0.015189915997325443 s\n",
      "Person: 94 Time: 0.015423749995534308 s\n",
      "Person: 95 Time: 0.016122500004712492 s\n",
      "Person: 96 Time: 0.014811082990490831 s\n",
      "Person: 97 Time: 0.01966362500388641 s\n",
      "Person: 98 Time: 0.0162209160043858 s\n",
      "Person: 99 Time: 0.01689995800552424 s\n",
      "Person: 100 Time: 0.0398594169964781 s\n",
      "Person: 101 Time: 0.014937291998649016 s\n",
      "Person: 102 Time: 0.018945917006931268 s\n",
      "Person: 103 Time: 0.01350645799539052 s\n",
      "Person: 104 Time: 0.017946416002814658 s\n",
      "Person: 105 Time: 0.03904179199889768 s\n",
      "Person: 106 Time: 0.023102833001757972 s\n",
      "Person: 107 Time: 0.014277791997301392 s\n",
      "Person: 108 Time: 0.011067416999139823 s\n",
      "Person: 109 Time: 0.016834417008794844 s\n",
      "Person: 110 Time: 0.03482912499748636 s\n",
      "Person: 111 Time: 0.03527079201012384 s\n",
      "Person: 112 Time: 0.013935916998889297 s\n",
      "Person: 113 Time: 0.020186249996186234 s\n",
      "Person: 114 Time: 0.018808833992807195 s\n",
      "Person: 115 Time: 0.0134703750081826 s\n",
      "Person: 116 Time: 0.0015845839952817187 s\n",
      "Person: 117 Time: 0.016314791006152518 s\n",
      "Person: 118 Time: 0.015527499999734573 s\n",
      "Person: 119 Time: 0.014671042008558288 s\n",
      "Person: 120 Time: 0.011847208006656729 s\n",
      "Person: 121 Time: 0.01439112500520423 s\n",
      "Person: 122 Time: 0.020759500010171905 s\n",
      "Person: 123 Time: 0.014019084002939053 s\n",
      "Person: 124 Time: 0.016100042004836723 s\n",
      "Person: 125 Time: 0.0218690420006169 s\n",
      "Person: 126 Time: 0.013640832999954 s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerson:\u001b[39m\u001b[38;5;124m\"\u001b[39m, idx, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m s\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# if time > 0.2 else '')\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# TODO: poner la minimalidad\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m successes \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m valid \u001b[38;5;66;03m# and (((state_p.metadata.max_values < p_new) | (state_p.metadata.min_values > p_new)).sum() == 0))\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# print(\"Person:\", idx, \"Rate of grad desc:\",minimality_check(p, p_new, weights, ep, model))\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/TFG/src/checks.py:76\u001b[0m, in \u001b[0;36mChecks.__call__\u001b[0;34m(self, person, person_new, weights)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe new person is an outlier.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstability_check_global\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperson_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model is not stable around this point\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/TFG/src/checks.py:244\u001b[0m, in \u001b[0;36mChecks.stability_check_global\u001b[0;34m(self, person, person_new, weights)\u001b[0m\n\u001b[1;32m    234\u001b[0m points \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m    235\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m-\u001b[39mnoise, noise, (num_points, person\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;241m*\u001b[39m (weights \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy() \n\u001b[1;32m    237\u001b[0m     \u001b[38;5;241m+\u001b[39m person\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    238\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32,\n\u001b[1;32m    239\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m person_close \u001b[38;5;129;01min\u001b[39;00m points:\n\u001b[0;32m--> 244\u001b[0m     person_close_new, _ \u001b[38;5;241m=\u001b[39m \u001b[43mnewton_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperson_close\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreg_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg_clamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreg_clamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m     diff_factor \u001b[38;5;241m=\u001b[39m distance(person_new, person_close_new, weights) \u001b[38;5;241m/\u001b[39m distance(person, person_close, weights)\n\u001b[1;32m    246\u001b[0m     max_diff_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(max_diff_factor, diff_factor)\n",
      "File \u001b[0;32m~/Documents/TFG/src/counterfactual.py:229\u001b[0m, in \u001b[0;36mnewton_op\u001b[0;34m(model, person, metadata, weights, delta_threshold, max_epochs, reg_int, reg_vars, reg_clamp, print_, der)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (weights \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m###################################################\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m### Si solo tenemos una variables activa que cambiar\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m###################################################\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     derivative \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(\n\u001b[1;32m    221\u001b[0m         model(person_new\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))[\u001b[38;5;241m0\u001b[39m][metadata\u001b[38;5;241m.\u001b[39mgood_class],\n\u001b[1;32m    222\u001b[0m         person_new,\n\u001b[1;32m    223\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    224\u001b[0m         allow_unused\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    225\u001b[0m     )[\u001b[38;5;241m0\u001b[39m][weights \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    226\u001b[0m     delta \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    227\u001b[0m         (\n\u001b[1;32m    228\u001b[0m             \u001b[38;5;241m0.3\u001b[39m \u001b[38;5;241m*\u001b[39m (\n\u001b[0;32m--> 229\u001b[0m                 model(\u001b[43mperson_new\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)[\u001b[38;5;241m0\u001b[39m][metadata\u001b[38;5;241m.\u001b[39mgood_class]\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;241m-\u001b[39m state\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mthreshold\n\u001b[1;32m    231\u001b[0m             )\u001b[38;5;241m/\u001b[39m derivative,\n\u001b[1;32m    232\u001b[0m             torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m    233\u001b[0m         ),\n\u001b[1;32m    234\u001b[0m         dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# lr = 0.6\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;66;03m# delta_threshold /= 4\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mabs\u001b[39m(thres_term) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.1\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m first_time \u001b[38;5;129;01mand\u001b[39;00m state\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;66;03m###################################################\u001b[39;00m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;66;03m### Se estamos medio cerca de la solución, aplicamos reg_int y eliminamos reg_vars\u001b[39;00m\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;66;03m###################################################\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import src.counterfactual\n",
    "import src.checks\n",
    "importlib.reload(src.counterfactual)\n",
    "importlib.reload(src.checks)\n",
    "from src.counterfactual import newton_op\n",
    "from src.checks import Checks\n",
    "\n",
    "reg_int = False\n",
    "reg_clamp = False\n",
    "metadata.threshold = 0.5 + 1e-7\n",
    "\n",
    "successes = 0\n",
    "epochs = 0\n",
    "bad_idxs = []\n",
    "total = 0\n",
    "total_time = []\n",
    "check = Checks(model, metadata, reg_int=reg_int, reg_clamp=reg_clamp)\n",
    "for idx, p in enumerate(inputs_useful[:176]):\n",
    "\n",
    "    from time import perf_counter\n",
    "    \n",
    "    s = perf_counter()\n",
    "    p_new, ep = newton_op(model, p, metadata, weights, 0.2, reg_int=reg_int, reg_clamp=reg_clamp, der=False)\n",
    "    time = perf_counter()-s\n",
    "    print(\"Person:\", idx, f'Time: {time} s') # if time > 0.2 else '')\n",
    "    # TODO: poner la minimalidad\n",
    "    valid = check(p, p_new, weights)\n",
    "    successes += valid # and (((state_p.metadata.max_values < p_new) | (state_p.metadata.min_values > p_new)).sum() == 0))\n",
    "    # print(\"Person:\", idx, \"Rate of grad desc:\",minimality_check(p, p_new, weights, ep, model))\n",
    "    epochs += ep.epochs\n",
    "    total += 1\n",
    "    total_time.append(time)\n",
    "    # if not valid:\n",
    "    #     bad_idxs.append(idx)\n",
    "        # print(idx, valid)\n",
    "print(\"Successes:\", successes, \"Total:\", total)\n",
    "print(\"Average epochs:\", epochs / total)\n",
    "print(\"Time:\", np.array(total_time).mean() , np.array(total_time).std() )\n",
    "print(\"Stability:\", np.array(check.diff_factors).mean(), '±', np.array(check.diff_factors).std())\n",
    "print(\"Success rate:\", successes / total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan 4.353627812117338 ± 5.806163177495694"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# successes = 0\n",
    "# bad_idxs = []\n",
    "# total = 0\n",
    "# for i, inputs in enumerate(test_data):\n",
    "#     print(i, end='\\r')\n",
    "#     outputs = model(inputs[0]).argmax(dim=1)\n",
    "#     inputs_useful = inputs[0][outputs == 1]\n",
    "#     for idx, p in enumerate(inputs_useful):\n",
    "#         _, ep = newton_op(model, p, weights, 0.1) #if idx not in [103, 105, 237, 406, 417, 450] else None\n",
    "#         # print(\"Person:\", idx, \"Success:\", not ep)\n",
    "#         successes += ep\n",
    "#         total += 1\n",
    "#         # if not ep:\n",
    "#         #     bad_idxs.append(idx)\n",
    "#     print(successes/total)\n",
    "# print(\"Successes:\", successes, \"Total:\", total)\n",
    "# print(\"Success rate:\", successes / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epochs: 8.909090909090908\n",
      "Time: 0.03304126153869385 0.025611918371383748\n",
      "Stability: nan ± nan\n",
      "Success rate: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Average epochs:\", epochs / total)\n",
    "print(\"Time:\", np.array(total_time).mean() , np.array(total_time).std() )\n",
    "print(\"Stability:\", np.array(check.diff_factors).mean(), '±', np.array(check.diff_factors).std())\n",
    "print(\"Success rate:\", successes / total)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
